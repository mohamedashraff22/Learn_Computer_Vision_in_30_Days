{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad2fa1d",
   "metadata": {},
   "source": [
    "# **Edge Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd3f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(os.path.join('..', 'assets', 'footballPlayer.jpg'))\n",
    "\n",
    "img_edge = cv2.Canny(img, 100, 200) # 100 is the minVal and 200 is the maxVal\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Edge Detected Image', img_edge)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilate : means to expand the white region in the image or to increase the size of foreground objects.\n",
    "\n",
    "img_dilated = cv2.dilate(img_edge, None, iterations=1) # None means using the default 3x3 kernel\n",
    "\n",
    "# img_dilated = cv2.dilate(img_edge, np.ones((5,5), dtype=np.int8)) # make it 3*3 will make it less thicker\n",
    "\n",
    "cv2.imshow('Original edged Image', img_edge)  \n",
    "cv2.imshow('Dilated Image', img_dilated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7b78c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erode : means to erode away the boundaries of foreground object or to decrease the size of foreground objects (opposite to dilate).\n",
    "img_eroded = cv2.erode(img_edge, np.ones((2,2), dtype=np.int8)) # None means using the default 3x3 kernel\n",
    "cv2.imshow('Original edged Image', img_edge)\n",
    "cv2.imshow('Eroded Image', img_eroded)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad70e17",
   "metadata": {},
   "source": [
    "#### **Refrences:**\n",
    "https://opencv.org/blog/edge-detection-using-opencv/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c385c2",
   "metadata": {},
   "source": [
    "# **Notes**\n",
    "\n",
    "## **Core Algorithm: Canny Edge Detector**\n",
    "\n",
    "* **Function:** The lesson focuses on the **Canny Edge Detector**, which is implemented using `cv2.Canny()`.\n",
    "* **Alternative Methods:** The instructor briefly mentions other operators like **Sobel** and **Laplacian** but focuses on Canny for this lesson.\n",
    "* **Syntax:** `cv2.Canny(image, threshold1, threshold2)`.\n",
    "* **Parameters (Hysteresis Thresholding):**\n",
    "    * The function requires two integer arguments (e.g., 100 and 200).\n",
    "    * These values represent the **min** and **max** thresholds for the hysteresis process.\n",
    "    * **Tuning:** The instructor recommends using **trial and error** to find the best numbers. The algorithm is robust, so a range of values (e.g., 100-200 or 50-200) often produces good results.\n",
    "\n",
    "\n",
    "\n",
    "## **Morphological Transformations**\n",
    "\n",
    "#### The instructor introduces two additional functions often used to improve the visualization of edges:\n",
    "\n",
    "* **Dilation (`cv2.dilate`):**\n",
    "    * **Effect:** It makes the white regions (the detected edges) **thicker**.\n",
    "    * **Syntax:** `cv2.dilate(image, kernel, iterations=1)`.\n",
    "    * **Kernel:** Requires a NumPy array (e.g., a 5x5 matrix of ones) to define how much to thicken the lines.\n",
    "    * **Use Case:** Useful for making faint edges more visible or connecting broken lines.\n",
    "\n",
    "\n",
    "* **Erosion (`cv2.erode`):**\n",
    "    * **Effect:** It makes the white regions **thinner**.\n",
    "    * **Syntax:** `cv2.erode(image, kernel, iterations=1)`.\n",
    "    * **Relationship:** It performs the opposite operation of dilation.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193b994",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Algorithms:**\n",
    "\n",
    "### **1. Canny Edge Detection Algorithm**\n",
    "\n",
    "The Canny algorithm is a multi-stage process designed to be an \"optimal\" edge detector. It doesn't just find changes in color; it cleans them up to produce thin, continuous lines.\n",
    "\n",
    "1. **Noise Reduction (Gaussian Filter):**\n",
    "* Since edge detection is very sensitive to noise (random speckles), the algorithm first smoothes the image using a Gaussian blur kernel (like a weighted average) to remove \"false\" edges caused by noise.\n",
    "\n",
    "\n",
    "2. **Gradient Calculation:**\n",
    "* It calculates the intensity gradient of the image (typically using Sobel kernels).\n",
    "* It determines both the **magnitude** (how strong the edge is) and the **direction** (where the edge is pointing) for every pixel.\n",
    "\n",
    "\n",
    "3. **Non-Maximum Suppression (Edge Thinning):**\n",
    "* The algorithm scans every pixel along the gradient direction.\n",
    "* If a pixel is **not** the \"peak\" (maximum value) compared to its neighbors in the direction of the edge, it is set to zero (suppressed).\n",
    "* *Result:* This converts thick, blurry edges into thin, sharp lines (1 pixel wide).\n",
    "\n",
    "\n",
    "4. **Double Thresholding:**\n",
    "* This separates pixels into three categories based on the two threshold values you provided (e.g., 100 and 200):\n",
    "* **Strong Edge:** Intensity > High Threshold (Definitely an edge).\n",
    "* **Weak Edge:** Intensity is between Low and High Threshold (Maybe an edge, maybe noise).\n",
    "* **Non-Edge:** Intensity < Low Threshold (Discarded).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "5. **Edge Tracking by Hysteresis:**\n",
    "* The algorithm decides what to do with the \"Weak Edges.\"\n",
    "* If a Weak Edge pixel is connected to a Strong Edge pixel, it is preserved.\n",
    "* If a Weak Edge pixel is isolated (not connected to a strong one), it is discarded as noise.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Sobel Operator Algorithm**\n",
    "\n",
    "The Sobel operator is a discrete differentiation operator. It computes an approximation of the gradient of the image intensity function.\n",
    "\n",
    "1. **Convolution (X and Y):**\n",
    "* The algorithm slides two  kernels (matrices) over the image:\n",
    "* **Kernel **: Calculates the difference in intensity horizontally (detects vertical edges).\n",
    "* **Kernel **: Calculates the difference in intensity vertically (detects horizontal edges).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. **Gradient Magnitude Calculation:**\n",
    "* For each pixel, it combines the X and Y results to find the total edge strength using the Pythagorean theorem:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. **Gradient Direction Calculation (Optional):**\n",
    "* It calculates the angle of the edge (perpendicular to the gradient):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Laplacian Algorithm**\n",
    "\n",
    "Unlike Sobel (which uses the first derivative/slope), Laplacian uses the **second derivative** (how fast the slope is changing). It is isotropic (rotation invariant), meaning it detects edges equally well in all directions.\n",
    "\n",
    "1. **Calculate Second Derivative:**\n",
    "* The algorithm calculates the sum of the second derivatives in the x and y directions.\n",
    "* Mathematically, it looks for the \"curvature\" of the intensity graph.\n",
    "\n",
    "\n",
    "2. **Zero-Crossing Detection:**\n",
    "* In a first derivative (Sobel), an edge is a peak (maximum value).\n",
    "* In a second derivative (Laplacian), an edge is where the values cross from positive to negative (a **zero-crossing**).\n",
    "* The algorithm identifies edges by locating these zero-crossing points.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f2f54",
   "metadata": {},
   "source": [
    "---\n",
    "# **Coding**\n",
    "\n",
    "### **1. Canny Edge Detection**\n",
    "\n",
    "This is the method recommended in the lesson for its robustness.\n",
    "\n",
    "* **Step 1:** Read the image.\n",
    "* **Step 2:** Call `cv2.Canny(image, threshold1, threshold2)`.\n",
    "* **Step 3:** Tune the two thresholds (hysteresis). The instructor suggests trial and error, often starting with values like 100 and 200.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image.jpg')\n",
    "# Canny handles internal blurring, but reducing noise externally is often good practice\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "cv2.imshow('Canny', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "These are the **Hysteresis Thresholds**:\n",
    "\n",
    "* **100 (MinVal):** Any gradient value **below** this is strictly discarded (considered not an edge).\n",
    "* **200 (MaxVal):** Any gradient value **above** this is strictly accepted (considered a \"sure\" edge).\n",
    "* **Between 100 and 200:** These are \"weak\" edges. They are only kept if they are connected to a \"sure\" edge; otherwise, they are discarded.\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Sobel Operator**\n",
    "\n",
    "The Sobel operator calculates the gradient (change in intensity) separately for the horizontal (x) and vertical (y) directions.\n",
    "\n",
    "* **Step 1:** Read the image and convert to **Grayscale**.\n",
    "* **Step 2:** Apply a Gaussian Blur to remove noise (Sobel is sensitive to noise).\n",
    "* **Step 3:** Calculate gradients in X and Y direction using `cv2.Sobel`.\n",
    "* **Step 4:** Combine the two gradients.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE) # cv2.IMREAD_GRAYSCALE -> load the image directly as a single-channel grayscale image, ignoring any color information.\n",
    "img_blur = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "# Sobel X: Vertical edges (dx=1, dy=0)\n",
    "sobelx = cv2.Sobel(img_blur, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "# Sobel Y: Horizontal edges (dx=0, dy=1)\n",
    "sobely = cv2.Sobel(img_blur, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "cv2.imshow('Sobel X', sobelx)\n",
    "cv2.imshow('Sobel Y', sobely)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "Here is the very brief breakdown:\n",
    "\n",
    "* **`dx`**: The order of the derivative in **x**. Setting `dx=1` tells OpenCV to calculate the change in pixel intensity horizontally (finding vertical edges).\n",
    "* **`dy`**: The order of the derivative in **y**. Setting `dy=1` tells OpenCV to calculate the change in pixel intensity vertically (finding horizontal edges).\n",
    "* **`ksize`**: The **Kernel Size**. It defines the width and height of the square window (matrix) used to calculate the derivative (e.g., `5` means a  window).\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Laplacian Edge Detector**\n",
    "\n",
    "The Laplacian calculates the second derivative of the image intensity. It detects edges where the intensity changes rapidly in *any* direction.\n",
    "\n",
    "* **Step 1:** Read the image and convert to **Grayscale**.\n",
    "* **Step 2:** Apply a Gaussian Blur (crucial, as Laplacian is very sensitive to noise).\n",
    "* **Step 3:** Apply `cv2.Laplacian`.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img_blur = cv2.GaussianBlur(img, (3, 3), 0) # (3,3) -> kernal size, 0 -> st deviation.\n",
    "\n",
    "# The second argument (cv2.CV_64F) allows for negative gradients (black-to-white transitions)\n",
    "laplacian = cv2.Laplacian(img_blur, cv2.CV_64F)\n",
    "\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "\n",
    "### **Why we use cv2.CV_64F (64-bit float) instead of the standard 8-bit integer for Sobel and Laplacian?** \n",
    "\n",
    "We use `cv2.CV_64F` because **edge detection involves negative numbers**, which 8-bit images cannot store.\n",
    "\n",
    "* **The Issue:** Standard images are `uint8` (0 to 255). They cannot hold negative values.\n",
    "* **The Math:** An edge is a change in brightness.\n",
    "* **Dark  Bright:** Positive change (e.g., ).\n",
    "* **Bright  Dark:** Negative change (e.g., ).\n",
    "\n",
    "\n",
    "* **The Result:** If you use `uint8`, all negative edges (bright-to-dark transitions) are clamped to **0** (black) and lost.\n",
    "* **The Fix:** We use `cv2.CV_64F` (floats) to keep the negative numbers, then take the absolute value later to view the edges correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-computer-vision-in-30-days (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
