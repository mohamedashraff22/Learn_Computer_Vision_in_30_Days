{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f0df55",
   "metadata": {},
   "source": [
    "# **YOLOv8n**\n",
    "\n",
    "**YOLOv8n** stands for **YOLOv8 Nano**.\n",
    "\n",
    "It is the smallest, fastest, and most lightweight version of the YOLOv8 model family.\n",
    "\n",
    "In the YOLO naming convention (`yolov8n`, `yolov8s`, `yolov8m`, `yolov8l`, `yolov8x`), the letter at the end tells you the **Model Scale**. Think of it like T-shirt sizes for AI models.\n",
    "\n",
    "### 1. What makes it \"Nano\"?\n",
    "\n",
    "It has the fewest \"parameters\" (weights) and the simplest architecture depth.\n",
    "\n",
    "* **Speed:** Blisteringly fast. It can run in real-time on a CPU (like your laptop without a GPU) or even on edge devices like a Raspberry Pi or a mobile phone.\n",
    "* **Size:** The file size (`yolov8n.pt`) is tinyâ€”around **6 MB**.\n",
    "* **Accuracy:** It is the *least* accurate of the bunch. It might miss small objects or struggle with complex scenes that the larger models would catch easily.\n",
    "\n",
    "### 2. The Trade-off (The \"T-Shirt\" Sizes)\n",
    "\n",
    "Here is how `n` compares to its big brothers:\n",
    "\n",
    "| Model Name | Size | Speed (Inference) | Accuracy (mAP) | Compute Required |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **YOLOv8n (Nano)** | **~3M params** | **Fastest** ðŸš€ | Lowest | Mobile / CPU |\n",
    "| **YOLOv8s (Small)** | ~11M params | Fast | Good | Standard GPU |\n",
    "| **YOLOv8m (Medium)** | ~25M params | Balanced | Better | Good GPU |\n",
    "| **YOLOv8l (Large)** | ~43M params | Slow | High | Strong GPU |\n",
    "| **YOLOv8x (X-Large)** | ~68M params | Slowest | Highest ðŸŽ¯ | Server GPU |\n",
    "\n",
    "### 3. When should you use `yolov8n`?\n",
    "\n",
    "* **Development/Debugging:** When you are writing your code and just want to check if the pipeline works without waiting forever for training.\n",
    "* **Mobile Apps:** Android/iOS deployment where battery and memory are limited.\n",
    "* **Edge Devices:** Raspberry Pi, Jetson Nano, or simple security cameras.\n",
    "* **Real-time Video:** If you need 30+ FPS on a standard laptop CPU.\n",
    "\n",
    "### 4. When should you AVOID it?\n",
    "\n",
    "* **Small Objects:** If you are trying to detect tiny defects on a microchip or a bird far away in the sky, `yolov8n` will likely fail. You would need `yolov8m` or `yolov8l` for that.\n",
    "* **High Accuracy Criticality:** If missing a detection is dangerous (e.g., medical diagnosis), do not use Nano.\n",
    "\n",
    "**Quick Tip:** Start your project with **Nano**. If it works well enough, greatâ€”you save money and compute. If it's too dumb, simply switch the string in your code to `\"yolov8s.pt\"` or `\"yolov8m.pt\"`. You don't need to change any other code.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "Out of the box (without you doing any extra work), the standard pre-trained YOLOv8n model can detect **80 specific \"common\" objects**.\n",
    "\n",
    "This is because it comes pre-trained on a famous dataset called **COCO** (Common Objects in Context).\n",
    "\n",
    "Here is exactly what it can see in your videos right now:\n",
    "\n",
    "### 1. The \"COCO 80\" List (Categorized)\n",
    "\n",
    "If you run `yolov8n.pt` on a video, it will recognize these items:\n",
    "\n",
    "* **People:**\n",
    "* `person` (Men, women, childrenâ€”it just says \"person\")\n",
    "\n",
    "\n",
    "* **Vehicles:**\n",
    "* `bicycle`, `car`, `motorcycle`, `airplane`, `bus`, `train`, `truck`, `boat`\n",
    "\n",
    "\n",
    "* **Animals:**\n",
    "* `bird`, `cat`, `dog`, `horse`, `sheep`, `cow`, `elephant`, `bear`, `zebra`, `giraffe`\n",
    "\n",
    "\n",
    "* **Traffic & Outdoor:**\n",
    "* `traffic light`, `fire hydrant`, `stop sign`, `parking meter`, `bench`\n",
    "\n",
    "\n",
    "* **Accessories & Sports:**\n",
    "* `backpack`, `umbrella`, `handbag`, `tie`, `suitcase`, `frisbee`, `skis`, `snowboard`, `sports ball`, `kite`, `baseball bat`, `skateboard`, `surfboard`, `tennis racket`\n",
    "\n",
    "\n",
    "* **Electronics:**\n",
    "* `tv`, `laptop`, `mouse`, `remote`, `keyboard`, `cell phone`\n",
    "\n",
    "\n",
    "* **Kitchen & Food:**\n",
    "* `bottle`, `wine glass`, `cup`, `fork`, `knife`, `spoon`, `bowl`, `banana`, `apple`, `sandwich`, `orange`, `broccoli`, `carrot`, `hot dog`, `pizza`, `donut`, `cake`, `microwave`, `oven`, `toaster`, `refrigerator`\n",
    "\n",
    "\n",
    "* **Furniture & Indoor:**\n",
    "* `chair`, `couch`, `potted plant`, `bed`, `dining table`, `toilet`, `book`, `clock`, `vase`, `scissors`, `teddy bear`, `hair drier`, `toothbrush`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Can it detect other things? (The \"Pro\" Answer)\n",
    "\n",
    "**Yes, absolutely.** This is the most important part for a future engineer.\n",
    "\n",
    "The list above is just the *default*. You can train YOLO to detect **anything** visible to the human eye, provided you have the data.\n",
    "\n",
    "* **Medical:** Detect tumors in X-rays.\n",
    "* **Industrial:** Detect cracks in pipes or rust on machines.\n",
    "* **Agriculture:** Detect ripe vs. rotten tomatoes.\n",
    "* **Military:** Detect specific types of tanks or drones.\n",
    "\n",
    "To do this, you simply \"fine-tune\" the model on your own photos of those objects.\n",
    "\n",
    "### 3. Special \"Video\" Capability: Tracking\n",
    "\n",
    "Since you asked about **videos**, there is a special feature you should know.\n",
    "\n",
    "In a video, objects move. If a car is in Frame 1 and then moves slightly in Frame 2, YOLO needs to know **it is the same car**, not a new one.\n",
    "\n",
    "YOLOv8 has a built-in tracker. It assigns a unique **ID** to each object.\n",
    "\n",
    "* **Without Tracking:** \"Car\", \"Car\", \"Car\" (The model doesn't know if it's the same one).\n",
    "* **With Tracking:** \"Car #1\", \"Car #1\", \"Car #1\" (It follows that specific car across the video).\n",
    "\n",
    "**Code for Video Tracking:**\n",
    "\n",
    "```python\n",
    "# Instead of model.predict(), use model.track()\n",
    "results = model.track(source=\"video.mp4\", show=True)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
